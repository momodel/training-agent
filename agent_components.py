from typing import Dict, Any, List
import os
import json
import pandas as pd
from openai import OpenAI
from utils import RetryHandler, LLMError, ValidationError, validate_llm_response
import logging
from prompts import (
    get_analysis_prompt,
    get_theory_prompt,
    get_code_prompt,
    get_exercises_prompt,
    get_content_organization_prompt
)

class DatasetAnalyzer:
    """æ•°æ®é›†åˆ†æç»„ä»¶"""
    def __init__(self, llm_client: OpenAI, *, config=None):
        self.llm = llm_client
        self.retry_handler = RetryHandler()
        self.logger = logging.getLogger(__name__)
        self.max_preview_rows = config.preview.max_preview_rows if config else 5
        self.max_preview_size = config.preview.max_preview_size if config else 2000
        self.model = config.llm.model if config else "gpt-4o"
    
    def _get_dataset_preview(self, dataset_path: str) -> str:
        """è·å–æ•°æ®é›†é¢„è§ˆä¿¡æ¯"""
        file_type = self._get_file_type(dataset_path)
        preview_info = []
        
        try:
            if file_type == 'csv':
                df = pd.read_csv(dataset_path, nrows=self.max_preview_rows)
                preview_info.extend([
                    "æ•°æ®é›†åŸºæœ¬ä¿¡æ¯ï¼š",
                    f"æ€»è¡Œæ•°ï¼š{len(pd.read_csv(dataset_path, usecols=[0]))}", # åªè¯»å–ç¬¬ä¸€åˆ—æ¥è·å–æ€»è¡Œæ•°
                    f"åˆ—æ•°ï¼š{len(df.columns)}",
                    f"åˆ—åï¼š{', '.join(df.columns)}",
                    "\næ•°æ®ç±»å‹ï¼š",
                    df.dtypes.to_string(),
                    "\nå‰å‡ è¡Œæ•°æ®ï¼š",
                    df.head().to_string()
                ])
            
            elif file_type == 'excel':
                df = pd.read_excel(dataset_path, nrows=self.max_preview_rows)
                preview_info.extend([
                    "æ•°æ®é›†åŸºæœ¬ä¿¡æ¯ï¼š",
                    f"æ€»è¡Œæ•°ï¼š{len(pd.read_excel(dataset_path, usecols=[0]))}",
                    f"åˆ—æ•°ï¼š{len(df.columns)}",
                    f"åˆ—åï¼š{', '.join(df.columns)}",
                    "\næ•°æ®ç±»å‹ï¼š",
                    df.dtypes.to_string(),
                    "\nå‰å‡ è¡Œæ•°æ®ï¼š",
                    df.head().to_string()
                ])
            
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{file_type}")
            
            # æ·»åŠ ç¼ºå¤±å€¼ä¿¡æ¯
            missing_info = df.isnull().sum()
            if missing_info.any():
                preview_info.extend([
                    "\nç¼ºå¤±å€¼ä¿¡æ¯ï¼š",
                    missing_info.to_string()
                ])
            
            # æ·»åŠ æ•°å€¼åˆ—çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
            if not numeric_cols.empty:
                preview_info.extend([
                    "\næ•°å€¼åˆ—ç»Ÿè®¡ä¿¡æ¯ï¼š",
                    df[numeric_cols].describe().to_string()
                ])
            
            preview_text = "\n".join(preview_info)
            
            # å¦‚æœé¢„è§ˆæ–‡æœ¬å¤ªé•¿ï¼Œè¿›è¡Œæˆªæ–­
            if len(preview_text) > self.max_preview_size:
                preview_text = preview_text[:self.max_preview_size] + "..."
            
            return preview_text
            
        except Exception as e:
            raise ValueError(f"è¯»å–æ•°æ®é›†æ—¶å‡ºé”™ï¼š{str(e)}")

    def _get_file_type(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶ç±»å‹"""
        ext = os.path.splitext(file_path)[1].lower()
        supported_types = {
            '.csv': 'csv',
            '.xlsx': 'excel',
            '.xls': 'excel'
        }
        
        if ext not in supported_types:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{ext}")
        
        return supported_types[ext]

    def _get_llm_analysis(self, dataset_preview: str) -> str:
        """è·å– LLM åˆ†æç»“æœ"""
        try:
            print("æ­£åœ¨å‘é€è¯·æ±‚åˆ° LLM...")
            response = self.llm.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": get_analysis_prompt(dataset_preview)
                }]
            )
            print("LLM å“åº”æ¥æ”¶å®Œæˆ")
            return response.choices[0].message.content
        except Exception as e:
            print(f"LLM è°ƒç”¨å‡ºé”™: {str(e)}")
            raise LLMError(f"LLM è°ƒç”¨å¤±è´¥: {str(e)}")

    def _parse_analysis_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æ LLM çš„åˆ†æç»“æœ"""
        print("å¼€å§‹è§£æ LLM å“åº”...")
        print(f"å“åº”å†…å®¹: {response_text[:200]}...")  # åªæ‰“å°å‰200ä¸ªå­—ç¬¦
        
        # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤ Markdown ä»£ç å—æ ‡è®°
        def clean_json_response(text: str) -> str:
            # ç§»é™¤ ```json å’Œ ``` æ ‡è®°
            text = text.replace("```json", "").replace("```", "")
            # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½å­—ç¬¦
            text = text.strip()
            return text
        
        try:
            # æ¸…ç†å¹¶å°è¯•è§£æ JSON
            print("å°è¯•è§£æ JSON...")
            cleaned_response = clean_json_response(response_text)
            result = json.loads(cleaned_response)
            print("JSON è§£ææˆåŠŸ")
            
            # éªŒè¯å¿…è¦çš„å­—æ®µ
            required_fields = ['data_type', 'task_type', 'features', 'target', 'preprocessing_steps']
            missing_fields = [field for field in required_fields if field not in result]
            
            if missing_fields:
                print(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
                raise ValueError(f"åˆ†æç»“æœç¼ºå°‘å¿…è¦å­—æ®µï¼š{', '.join(missing_fields)}")
            
            print("æ‰€æœ‰å¿…è¦å­—æ®µéƒ½å­˜åœ¨")
            
            # æ ‡å‡†åŒ–ç»“æœæ ¼å¼
            standardized_result = {
                'data_type': result['data_type'],
                'task_type': result['task_type'],
                'features': result['features'],
                'target': result['target'],
                'preprocessing_steps': result['preprocessing_steps']
            }
            
            print("ç»“æœæ ‡å‡†åŒ–å®Œæˆ")
            return standardized_result
            
        except json.JSONDecodeError as e:
            print(f"JSON è§£æå¤±è´¥: {str(e)}")
            # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œå°è¯•æå–å…³é”®ä¿¡æ¯
            try:
                print("å°è¯•é‡æ–°æ ¼å¼åŒ–å“åº”...")
                # é‡æ–°è¯·æ±‚ LLM æ ¼å¼åŒ–ç»“æœ
                format_prompt = f"""
                è¯·å°†ä»¥ä¸‹åˆ†æç»“æœè½¬æ¢ä¸ºæ ‡å‡†çš„ JSON æ ¼å¼ï¼ˆä¸è¦æ·»åŠ ä»»ä½• Markdown æ ‡è®°ï¼‰ï¼š
                {response_text}
                
                éœ€è¦åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                - data_type: æ•°æ®é›†ç±»å‹
                - task_type: ä»»åŠ¡ç±»å‹
                - features: ç‰¹å¾è¯´æ˜
                - target: ç›®æ ‡å˜é‡
                - preprocessing_steps: é¢„å¤„ç†æ­¥éª¤
                
                ç›´æ¥è¿”å› JSON å¯¹è±¡ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ ‡è®°ã€‚
                """
                
                format_response = self.llm.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": format_prompt}]
                )
                
                print("é‡æ–°æ ¼å¼åŒ–å®Œæˆï¼Œå°è¯•è§£ææ–°çš„å“åº”...")
                return self._parse_analysis_response(format_response.choices[0].message.content)
                
            except Exception as e:
                print(f"é‡æ–°æ ¼å¼åŒ–å¤±è´¥: {str(e)}")
                raise ValueError(f"æ— æ³•è§£æåˆ†æç»“æœï¼š{str(e)}")

    @RetryHandler().retry_on_exception
    def analyze_dataset(self, dataset_path: str) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM åˆ†ææ•°æ®é›†"""
        try:
            print("å¼€å§‹è¯»å–æ•°æ®é›†...")
            dataset_preview = self._get_dataset_preview(dataset_path)
            print("æ•°æ®é›†é¢„è§ˆè·å–å®Œæˆï¼Œæ­£åœ¨è°ƒç”¨ LLM åˆ†æ...")
            response = self._get_llm_analysis(dataset_preview)
            print("LLM åˆ†æå®Œæˆï¼Œæ­£åœ¨è§£æç»“æœ...")
            return self._parse_analysis_response(response)
        except Exception as e:
            self.logger.error(f"æ•°æ®é›†åˆ†æå¤±è´¥: {str(e)}")
            raise LLMError(f"æ•°æ®é›†åˆ†æå¤±è´¥: {str(e)}")

class ContentGenerator:
    """å†…å®¹ç”Ÿæˆç»„ä»¶"""
    def __init__(self, llm_client: OpenAI, *, config=None):
        self.llm = llm_client
        self.retry_handler = RetryHandler()
        self.logger = logging.getLogger(__name__)
        self.config = config
        self.model = config.llm.model if config else "gpt-4"
    
    def _get_llm_response(self, prompt: str) -> str:
        """è·å– LLM å“åº”"""
        try:
            response = self.llm.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
        except Exception as e:
            raise LLMError(f"LLM è°ƒç”¨å¤±è´¥: {str(e)}")

    def _validate_theory_content(self, content: str) -> None:
        """éªŒè¯ç†è®ºå†…å®¹"""
        if not content or len(content.strip()) < 100:
            raise ValidationError("ç†è®ºå†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º")
        
        # æ”¯æŒå¤šç§æ ‡é¢˜æ ¼å¼å’Œå˜ä½“
        title_patterns = {
            "ä»»åŠ¡å®šä¹‰": [
                "# ä»»åŠ¡å®šä¹‰ä¸ç›®æ ‡", "## ä»»åŠ¡å®šä¹‰ä¸ç›®æ ‡", 
                "ä»»åŠ¡å®šä¹‰ä¸ç›®æ ‡", "ä»»åŠ¡å®šä¹‰", "ç›®æ ‡å®šä¹‰"
            ],
            "æ•°æ®é›†ä»‹ç»": [
                "# æ•°æ®é›†ä»‹ç»ä¸åŠ è½½", "## æ•°æ®é›†ä»‹ç»ä¸åŠ è½½",
                "æ•°æ®é›†ä»‹ç»", "æ•°æ®é›†è¯´æ˜", "æ•°æ®åŠ è½½"
            ],
            "æ•°æ®æ¢ç´¢": [
                "# æ•°æ®æ¢ç´¢ä¸åˆ†æ", "## æ•°æ®æ¢ç´¢ä¸åˆ†æ",
                "æ•°æ®æ¢ç´¢", "æ•°æ®åˆ†æ", "æ¢ç´¢æ€§åˆ†æ"
            ],
            "ç‰¹å¾å·¥ç¨‹": [
                "# ç‰¹å¾å·¥ç¨‹ä¸é¢„å¤„ç†", "## ç‰¹å¾å·¥ç¨‹ä¸é¢„å¤„ç†",
                "ç‰¹å¾å·¥ç¨‹", "æ•°æ®é¢„å¤„ç†", "ç‰¹å¾å¤„ç†"
            ],
            "æ¨¡å‹æ„å»º": [
                "# æ¨¡å‹æ„å»ºä¸è®­ç»ƒ", "## æ¨¡å‹æ„å»ºä¸è®­ç»ƒ",
                "æ¨¡å‹æ„å»º", "æ¨¡å‹è®­ç»ƒ", "ç®—æ³•å®ç°"
            ]
        }
        
        # æ£€æŸ¥æ¯ä¸ªå¿…éœ€éƒ¨åˆ†
        missing_sections = []
        for section, patterns in title_patterns.items():
            if not any(pattern in content for pattern in patterns):
                missing_sections.append(section)
        
        # å¦‚æœå†…å®¹é•¿åº¦è¶³å¤Ÿä¸”åŒ…å«ä»£ç ç¤ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥é€‚å½“æ”¾å®½è¦æ±‚
        if len(content) >= 2000 and "```python" in content:
            # åªè¦æœ‰ä»»åŠ¡å®šä¹‰ã€æ•°æ®é›†ä»‹ç»å’Œæ¨¡å‹æ„å»ºå°±å¯ä»¥äº†
            missing_sections = [s for s in missing_sections if s in ["ä»»åŠ¡å®šä¹‰", "æ•°æ®é›†ä»‹ç»", "æ¨¡å‹æ„å»º"]]
        
        if missing_sections:
            raise ValidationError(f"ç†è®ºå†…å®¹ç¼ºå°‘ä»¥ä¸‹éƒ¨åˆ†: {', '.join(missing_sections)}")
        
        # æ£€æŸ¥å†…å®¹é•¿åº¦æ˜¯å¦åˆé€‚
        if len(content) < 1500:  # ä¿æŒæœ€å°é•¿åº¦è¦æ±‚
            raise ValidationError("ç†è®ºå†…å®¹é•¿åº¦ä¸è¶³ï¼Œè¯·ç¡®ä¿å†…å®¹å……åˆ†è¯¦ç»†")
    
    def _validate_code_content(self, content: str) -> None:
        """éªŒè¯ä»£ç å†…å®¹"""
        if not content or "```python" not in content:
            raise ValidationError("ä»£ç å†…å®¹æ— æ•ˆ")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„å¯¼å…¥è¯­å¥
        required_imports = ["pandas", "numpy", "sklearn"]
        for imp in required_imports:
            if imp not in content.lower():
                raise ValidationError(f"ä»£ç ç¼ºå°‘ {imp} åº“çš„å¯¼å…¥")
    
    def _validate_exercises_content(self, content: str) -> None:
        """éªŒè¯ç»ƒä¹ é¢˜å†…å®¹"""
        if not content or len(content.strip()) < 100:
            raise ValidationError("ç»ƒä¹ é¢˜å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º")

        # æ£€æŸ¥ç»ƒä¹ é¢˜æ•°é‡
        exercise_count = content.count("## ç»ƒä¹ ")
        if exercise_count < 3:
            raise ValidationError("ç»ƒä¹ é¢˜æ•°é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦3ä¸ªç»ƒä¹ é¢˜")

        # æ£€æŸ¥æ¯ä¸ªç»ƒä¹ é¢˜çš„ç»“æ„
        exercises = content.split("## ç»ƒä¹ ")[1:]  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºå­—ç¬¦ä¸²
        for i, exercise in enumerate(exercises, 1):
            if "### é—®é¢˜" not in exercise:
                raise ValidationError(f"ç»ƒä¹  {i} ç¼ºå°‘é—®é¢˜æè¿°")
            if "### å‚è€ƒç­”æ¡ˆ" not in exercise:
                raise ValidationError(f"ç»ƒä¹  {i} ç¼ºå°‘å‚è€ƒç­”æ¡ˆ")
            if len(exercise.strip()) < 50:
                raise ValidationError(f"ç»ƒä¹  {i} å†…å®¹è¿‡çŸ­")

    @RetryHandler().retry_on_exception
    def generate_theory(self, knowledge_points: List[str], dataset_info: Dict[str, Any]) -> str:
        """ç”Ÿæˆç†è®ºè§£é‡Šå†…å®¹"""
        try:
            response = self._get_llm_response(
                get_theory_prompt(knowledge_points, dataset_info)
            )
            self._validate_theory_content(response)
            return response
        except Exception as e:
            self.logger.error(f"ç†è®ºå†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise LLMError(f"ç†è®ºå†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    @RetryHandler().retry_on_exception
    def generate_code_examples(self, dataset_info: Dict[str, Any]) -> str:
        """ç”Ÿæˆä»£ç ç¤ºä¾‹"""
        try:
            response = self._get_llm_response(
                get_code_prompt(dataset_info)
            )
            self._validate_code_content(response)
            return response
        except Exception as e:
            self.logger.error(f"ä»£ç ç¤ºä¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise LLMError(f"ä»£ç ç¤ºä¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    @RetryHandler().retry_on_exception
    def generate_exercises(self, difficulty_level: str, dataset_info: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»ƒä¹ é¢˜"""
        try:
            response = self._get_llm_response(
                get_exercises_prompt(difficulty_level, dataset_info)
            )
            self._validate_exercises_content(response)
            return response
        except Exception as e:
            self.logger.error(f"ç»ƒä¹ é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise LLMError(f"ç»ƒä¹ é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")

class NotebookAssembler:
    """Notebook ç»„è£…ç»„ä»¶"""
    def __init__(self, llm_client: OpenAI, *, config=None):
        self.llm = llm_client
        self.retry_handler = RetryHandler()
        self.logger = logging.getLogger(__name__)
        self.config = config
        self.model = config.llm.model if config else "gpt-4"
        self.notebook_template = {
            "cells": [],
            "metadata": {
                "kernelspec": {
                    "display_name": "Python 3",
                    "language": "python",
                    "name": "python3"
                },
                "language_info": {
                    "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                    },
                    "file_extension": ".py",
                    "mimetype": "text/x-python",
                    "name": "python",
                    "nbconvert_exporter": "python",
                    "pygments_lexer": "ipython3",
                    "version": "3.8.0"
                }
            },
            "nbformat": 4,
            "nbformat_minor": 4
        }
    
    def _organize_content(self, content: Dict[str, Any]) -> str:
        """åˆ†æ®µç»„ç»‡å†…å®¹çš„é¡ºåºå’Œç»“æ„"""
        organized_parts = []
        
        # 1. å¤„ç†ç†è®ºå†…å®¹
        if "theory" in content:
            theory_prompt = f"""
è¯·ä¼˜åŒ–ä»¥ä¸‹ç†è®ºå†…å®¹çš„ç»“æ„å’Œç»„ç»‡ï¼Œç¡®ä¿å±‚æ¬¡æ¸…æ™°ï¼Œä¿æŒæ‰€æœ‰å†…å®¹å®Œæ•´ã€‚
ä¸»è¦å…³æ³¨ï¼š
1. æ ‡é¢˜å±‚çº§çš„åˆç†æ€§
2. å†…å®¹çš„è¿è´¯æ€§
3. ä¿æŒæ‰€æœ‰ä»£ç ç¤ºä¾‹
4. ç¡®ä¿æ•°æ®é›†ä»‹ç»ã€ä»»åŠ¡å®šä¹‰ç­‰æ ¸å¿ƒéƒ¨åˆ†å®Œæ•´

å†…å®¹å¦‚ä¸‹ï¼š
{content['theory']}
"""
            try:
                theory_response = self.llm.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": theory_prompt}]
                )
                organized_parts.append(theory_response.choices[0].message.content)
            except Exception as e:
                self.logger.warning(f"ç†è®ºå†…å®¹ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå†…å®¹: {str(e)}")
                organized_parts.append(content["theory"])
        
        # 2. å¤„ç†ä»£ç ç¤ºä¾‹ï¼ˆå¦‚æœæ˜¯ç‹¬ç«‹çš„ï¼‰
        if "code" in content and isinstance(content["code"], str):
            code_prompt = f"""
è¯·ä¼˜åŒ–ä»¥ä¸‹ä»£ç ç¤ºä¾‹çš„ç»„ç»‡ï¼Œç¡®ä¿ï¼š
1. ä»£ç é€»è¾‘æ¸…æ™°
2. æ³¨é‡Šå®Œæ•´
3. æ¯ä¸ªæ­¥éª¤éƒ½æœ‰å……åˆ†è¯´æ˜
4. ä¿æŒæ‰€æœ‰åŠŸèƒ½å®Œæ•´

ä»£ç ç¤ºä¾‹ï¼š
{content['code']}
"""
            try:
                code_response = self.llm.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": code_prompt}]
                )
                organized_parts.append(code_response.choices[0].message.content)
            except Exception as e:
                self.logger.warning(f"ä»£ç ç¤ºä¾‹ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå†…å®¹: {str(e)}")
                organized_parts.append(content["code"])
        
        # 3. å¤„ç†ç»ƒä¹ å†…å®¹
        if "exercises" in content:
            exercises_prompt = f"""
è¯·ä¼˜åŒ–ä»¥ä¸‹ç»ƒä¹ å†…å®¹çš„ç»„ç»‡ï¼Œç¡®ä¿ï¼š
1. ç»ƒä¹ é¢˜çš„éš¾åº¦é€’è¿›
2. é—®é¢˜æè¿°æ¸…æ™°
3. ç­”æ¡ˆè§£é‡Šè¯¦ç»†
4. ä¿æŒæ‰€æœ‰ç»ƒä¹ é¢˜å®Œæ•´

ç»ƒä¹ å†…å®¹ï¼š
{content['exercises']}
"""
            try:
                exercises_response = self.llm.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": exercises_prompt}]
                )
                organized_parts.append(exercises_response.choices[0].message.content)
            except Exception as e:
                self.logger.warning(f"ç»ƒä¹ å†…å®¹ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå†…å®¹: {str(e)}")
                organized_parts.append(content["exercises"])
        
        # åˆå¹¶æ‰€æœ‰å†…å®¹
        return "\n\n".join(organized_parts)

    def _parse_content(self, content: str) -> List[Dict[str, str]]:
        """è§£æ LLM è¿”å›çš„å†…å®¹ï¼Œå°†å…¶åˆ†å‰²æˆä¸åŒçš„éƒ¨åˆ†"""
        sections = []
        current_section = {"cell_type": "markdown", "source": []}
        lines = content.split("\n")
        i = 0
        
        def save_current_markdown():
            nonlocal current_section
            if current_section["source"]:
                sections.append({
                    "cell_type": "markdown",
                    "metadata": {},
                    "source": current_section["source"]
                })
                current_section = {"cell_type": "markdown", "source": []}
        
        while i < len(lines):
            line = lines[i].rstrip()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ Python ä»£ç å—çš„å¼€å§‹
            if line.strip() == "```python":
                # ä¿å­˜å½“å‰çš„ markdown å†…å®¹
                save_current_markdown()
                
                # æ”¶é›†ä»£ç å†…å®¹
                code_lines = []
                i += 1  # è·³è¿‡å¼€å§‹æ ‡è®°
                while i < len(lines) and not lines[i].strip() == "```":
                    code_lines.append(lines[i].rstrip())
                    i += 1
                
                # åˆ›å»ºä»£ç å•å…ƒæ ¼
                if code_lines:
                    sections.append({
                        "cell_type": "code",
                        "metadata": {},
                        "source": code_lines,
                        "execution_count": None,
                        "outputs": []
                    })
            else:
                # å¤„ç†æ™®é€šæ–‡æœ¬
                current_section["source"].append(line)
            i += 1
        
        # ä¿å­˜æœ€åçš„ markdown å†…å®¹
        save_current_markdown()
        
        return sections

    def _convert_to_ipynb(self, content: str) -> str:
        """å°†å†…å®¹è½¬æ¢ä¸º ipynb æ ¼å¼"""
        try:
            # è§£æå†…å®¹
            sections = self._parse_content(content)
            
            # åˆ›å»ºæ–°çš„ notebook
            notebook = self.notebook_template.copy()
            
            # æ·»åŠ æ ‡é¢˜
            notebook["cells"].append({
                "cell_type": "markdown",
                "metadata": {},
                "source": ["# æœºå™¨å­¦ä¹ å®è®­è¯¾ç¨‹\n\n"]
            })
            
            # æ·»åŠ å„ä¸ªéƒ¨åˆ†çš„å†…å®¹
            for section in sections:
                cell = {
                    "cell_type": section["cell_type"],
                    "metadata": {},
                }
                
                if section["cell_type"] == "markdown":
                    # Markdown å•å…ƒæ ¼ä½¿ç”¨å•ä¸ªå­—ç¬¦ä¸²
                    cell["source"] = ["\n".join(section["source"])]
                else:
                    # ä»£ç å•å…ƒæ ¼ä¿æŒæ¯è¡Œç‹¬ç«‹
                    cell["source"] = [line + "\n" for line in section["source"]]
                    # æœ€åä¸€è¡Œä¸éœ€è¦é¢å¤–çš„æ¢è¡Œç¬¦
                    if cell["source"]:
                        cell["source"][-1] = cell["source"][-1].rstrip("\n")
                    cell["execution_count"] = None
                    cell["outputs"] = []
                
                notebook["cells"].append(cell)
            
            # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
            return json.dumps(notebook, ensure_ascii=False, indent=2)
            
        except Exception as e:
            raise ValueError(f"è½¬æ¢ notebook æ ¼å¼æ—¶å‡ºé”™ï¼š{str(e)}")

    def _validate_notebook(self, notebook: str) -> None:
        """éªŒè¯ç”Ÿæˆçš„ notebook æ˜¯å¦æœ‰æ•ˆ"""
        try:
            notebook_dict = json.loads(notebook)
            required_fields = ['cells', 'metadata', 'nbformat', 'nbformat_minor']
            validate_llm_response(notebook_dict, required_fields)
            
            # éªŒè¯å•å…ƒæ ¼
            if not notebook_dict['cells']:
                raise ValidationError("Notebook ä¸èƒ½æ²¡æœ‰å†…å®¹")
            
            # éªŒè¯æ¯ä¸ªå•å…ƒæ ¼çš„æ ¼å¼
            for cell in notebook_dict['cells']:
                if 'cell_type' not in cell or 'source' not in cell:
                    raise ValidationError("å•å…ƒæ ¼æ ¼å¼æ— æ•ˆ")
                
        except json.JSONDecodeError:
            raise ValidationError("ç”Ÿæˆçš„ notebook ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼")

    def _show_structure_preview(self, content: str) -> None:
        """æ˜¾ç¤º notebook ç»“æ„é¢„è§ˆ"""
        print("\nğŸ“” Notebook ç»“æ„é¢„è§ˆ:")
        print("-" * 40)
        
        # æå–æ‰€æœ‰æ ‡é¢˜
        sections = []
        current_level = 0
        
        for line in content.split("\n"):
            if line.startswith("#"):
                # è®¡ç®—æ ‡é¢˜çº§åˆ«
                level = len(line.split()[0])
                title = line.strip("#").strip()
                sections.append("  " * (level - 1) + "- " + title)
        
        # æ˜¾ç¤ºç›®å½•ç»“æ„
        print("ç›®å½•ç»“æ„:")
        for section in sections:
            print(section)
        
        # ç»Ÿè®¡ä¿¡æ¯
        code_blocks = content.count("```python")
        print(f"\nåŒ…å« {code_blocks} ä¸ªä»£ç å—")
        
        print("-" * 40)

    @RetryHandler().retry_on_exception
    def create_notebook(self, content: Dict[str, Any]) -> str:
        """å°†æ‰€æœ‰å†…å®¹ç»„è£…æˆ Jupyter notebook"""
        try:
            organized_content = self._organize_content(content)
            
            # åœ¨è½¬æ¢ä¹‹å‰æ˜¾ç¤ºç»“æ„é¢„è§ˆ
            self._show_structure_preview(organized_content)
            
            notebook = self._convert_to_ipynb(organized_content)
            self._validate_notebook(notebook)
            return notebook
            
        except Exception as e:
            self.logger.error(f"Notebook åˆ›å»ºå¤±è´¥: {str(e)}")
            raise ValueError(f"Notebook åˆ›å»ºå¤±è´¥: {str(e)}") 