from typing import Dict, Any, List
import os
from openai import OpenAI
from agent_components import DatasetAnalyzer, ContentGenerator, NotebookAssembler
from interface import UserInput
from utils import ProgressManager
from config import Config
from datetime import datetime
import json

class AITrainingGenerator:
    """AI å®è®­ç”Ÿæˆå™¨"""
    def __init__(self, api_key: str, config_path: str = None):
        self.config = Config(config_path)
        self.llm_client = OpenAI(
            api_key=api_key,
            # base_url="https://open.momodel.cn/v1"
        )
        self.dataset_analyzer = DatasetAnalyzer(self.llm_client, config=self.config)
        self.content_generator = ContentGenerator(self.llm_client, config=self.config)
        self.notebook_assembler = NotebookAssembler(self.llm_client, config=self.config)
        self.user_input = UserInput()
        self.progress = ProgressManager()
        # æ·»åŠ ç¼“å­˜ç›®å½•
        self.cache_dir = os.path.join(self.config.output.output_dir, '.cache')
        os.makedirs(self.cache_dir, exist_ok=True)
    
    def _get_cache_path(self, step: str, dataset_path: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        dataset_name = os.path.splitext(os.path.basename(dataset_path))[0]
        return os.path.join(self.cache_dir, f"{dataset_name}_{step}.json")
    
    def _load_from_cache(self, step: str, dataset_path: str) -> Dict[str, Any]:
        """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
        cache_path = self._get_cache_path(step, dataset_path)
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {str(e)}")
        return None
    
    def _save_to_cache(self, step: str, dataset_path: str, data: Dict[str, Any]) -> None:
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        try:
            cache_path = self._get_cache_path(step, dataset_path)
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.warning(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {str(e)}")
    
    def generate_training(self, input_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå®è®­å†…å®¹çš„ä¸»æµç¨‹"""
        try:
            # 1. éªŒè¯ç”¨æˆ·è¾“å…¥
            self.user_input.validate_input(input_data)
            
            # 2. åˆ†ææ•°æ®é›†
            self.progress.start_step('dataset_analysis')
            dataset_info = self._load_from_cache('dataset_analysis', input_data['dataset_path'])
            if dataset_info is None:
                dataset_info = self.dataset_analyzer.analyze_dataset(input_data['dataset_path'])
                self._save_to_cache('dataset_analysis', input_data['dataset_path'], dataset_info)
            self.progress.complete_step('dataset_analysis')
            
            # 3. ç”Ÿæˆå†…å®¹
            content = self._generate_content(input_data, dataset_info)
            
            # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
            self._show_content_preview(content)
            
            # 4. ç»„è£… notebook
            self.progress.start_step('notebook_assembly')
            notebook = self._load_from_cache('notebook', input_data['dataset_path'])
            if notebook is None:
                notebook = self.notebook_assembler.create_notebook(content)
                self._save_to_cache('notebook', input_data['dataset_path'], notebook)
            self.progress.complete_step('notebook_assembly')
            
            # 5. ä¿å­˜ç»“æœ
            output_path = self._save_notebook(notebook, input_data['dataset_path'])
            
            print(f"\nâœ¨ å®è®­å†…å®¹ç”Ÿæˆå®Œæˆï¼æ–‡ä»¶ä¿å­˜åœ¨: {output_path}")
            return output_path
            
        except Exception as e:
            self._handle_error(e)
    
    def _generate_content(self, input_data: Dict[str, Any], dataset_info: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰€æœ‰éœ€è¦çš„å†…å®¹"""
        content = {}
        
        # 1. ç”Ÿæˆç†è®ºå†…å®¹
        self.progress.start_step('theory_generation')
        theory_cache = self._load_from_cache('theory', input_data['dataset_path'])
        if theory_cache is None:
            content['theory'] = self.content_generator.generate_theory(
                knowledge_points=input_data['knowledge_points'],
                dataset_info=dataset_info
            )
            self._save_to_cache('theory', input_data['dataset_path'], {'theory': content['theory']})
        else:
            content['theory'] = theory_cache['theory']
        self.progress.complete_step('theory_generation')
        
        # 2. ç”Ÿæˆä»£ç ç¤ºä¾‹
        self.progress.start_step('code_generation')
        code_cache = self._load_from_cache('code', input_data['dataset_path'])
        if code_cache is None:
            content['code_examples'] = self.content_generator.generate_code_examples(
                dataset_info=dataset_info
            )
            self._save_to_cache('code', input_data['dataset_path'], {'code_examples': content['code_examples']})
        else:
            content['code_examples'] = code_cache['code_examples']
        self.progress.complete_step('code_generation')
        
        # 3. ç”Ÿæˆç»ƒä¹ é¢˜
        self.progress.start_step('exercises_generation')
        exercises_cache = self._load_from_cache('exercises', input_data['dataset_path'])
        if exercises_cache is None:
            content['exercises'] = self.content_generator.generate_exercises(
                difficulty_level=input_data['difficulty_level'],
                dataset_info=dataset_info
            )
            self._save_to_cache('exercises', input_data['dataset_path'], {'exercises': content['exercises']})
        else:
            content['exercises'] = exercises_cache['exercises']
        self.progress.complete_step('exercises_generation')
        
        return content
    
    def _save_notebook(self, notebook: str, dataset_path: str) -> str:
        """ä¿å­˜ç”Ÿæˆçš„ notebook"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.config.output.output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        base_name = os.path.splitext(os.path.basename(dataset_path))[0]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S") if self.config.output.include_timestamp else ""
        file_name = f"{self.config.output.file_prefix}{base_name}{timestamp}.ipynb"
        output_path = os.path.join(self.config.output.output_dir, file_name)
        
        # ä¿å­˜æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(notebook)
        
        return output_path
    
    def _handle_error(self, error: Exception) -> None:
        """å¤„ç†é”™è¯¯"""
        error_map = {
            ValueError: "è¾“å…¥å‚æ•°é”™è¯¯",
            FileNotFoundError: "æ‰¾ä¸åˆ°æ•°æ®é›†æ–‡ä»¶",
            Exception: "ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"
        }
        
        error_type = type(error)
        error_message = error_map.get(error_type, error_map[Exception])
        
        print(f"é”™è¯¯: {error_message}")
        print(f"è¯¦ç»†ä¿¡æ¯: {str(error)}")
        raise error
    
    def _show_content_preview(self, content: Dict[str, Any]) -> None:
        """æ˜¾ç¤ºç”Ÿæˆå†…å®¹çš„é¢„è§ˆ"""
        print("\nğŸ“ ç”Ÿæˆå†…å®¹é¢„è§ˆ:")
        
        # ç†è®ºå†…å®¹é¢„è§ˆ
        if 'theory' in content:
            theory_preview = content['theory'][:self.config.preview.preview_length]
            print("\nç†è®ºéƒ¨åˆ†:")
            print("-" * 40)
            print(f"{theory_preview}...")
        
        # ä»£ç ç¤ºä¾‹é¢„è§ˆ
        if 'code_examples' in content:
            code_preview = self._extract_code_preview(content['code_examples'])
            print("\nä»£ç ç¤ºä¾‹:")
            print("-" * 40)
            print(code_preview)
        
        # ç»ƒä¹ é¢˜é¢„è§ˆ
        if 'exercises' in content:
            print("\nç»ƒä¹ é¢˜:")
            print("-" * 40)
            exercises = content['exercises'].split("## ç»ƒä¹ ")
            exercise_count = len(exercises) - 1  # å‡å»ç¬¬ä¸€ä¸ªç©ºåˆ†ç‰‡
            print(f"å…±ç”Ÿæˆ {exercise_count} ä¸ªç»ƒä¹ é¢˜")
            
            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç»ƒä¹ é¢˜çš„é¢„è§ˆ
            if exercise_count > 0:
                first_exercise = exercises[1]  # ç¬¬ä¸€ä¸ªå®é™…çš„ç»ƒä¹ é¢˜
                print("\nç¬¬ä¸€ä¸ªç»ƒä¹ é¢˜é¢„è§ˆ:")
                # æå–é—®é¢˜éƒ¨åˆ†
                if "### é—®é¢˜" in first_exercise:
                    question = first_exercise.split("### é—®é¢˜")[1].split("###")[0]
                    print(f"é—®é¢˜: {question[:self.config.preview.preview_length].strip()}...")
        
        print("\n" + "-" * 40)
    
    def _extract_code_preview(self, code_content: str) -> str:
        """æå–ä»£ç ç¤ºä¾‹çš„é¢„è§ˆ"""
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä»£ç å—
        code_blocks = code_content.split("```python")
        if len(code_blocks) > 1:
            first_block = code_blocks[1].split("```")[0]
            # è·å–å‰å‡ è¡Œä»£ç 
            code_lines = first_block.strip().split("\n")[:5]
            return "\n".join(code_lines) + "\n..."
        return "æœªæ‰¾åˆ°ä»£ç å—"

def create_training(api_key: str, input_data: Dict[str, Any], config_path: str = None) -> str:
    """ä¾¿æ·å‡½æ•°ï¼Œç”¨äºåˆ›å»ºå®è®­å†…å®¹"""
    generator = AITrainingGenerator(api_key, config_path)
    return generator.generate_training(input_data) 